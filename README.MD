 
# ğŸ Road Line Detection with Lightweight U-Net

A real-time road line detection system optimized for NVIDIA Jetson Nano, designed for autonomous navigation on racing tracks and laboratory environments.

## ğŸ“‹ Overview

This project implements a lightweight U-Net architecture for semantic segmentation of road lines, specifically optimized for:
- **Real-time inference** on NVIDIA Jetson Nano (30+ FPS)
- **Curved track detection** with tight turns
- **Yellow and white line recognition**
- **Varying lighting conditions**
- **Model size**: 15-25 MB for optimal performance

## ğŸ¯ Key Features

- **Lightweight Architecture**: Optimized U-Net with attention mechanisms
- **Real-time Performance**: 30+ FPS on Jetson Nano
- **Robust Detection**: Handles curved tracks, shadows, and lighting variations


## ğŸ—ï¸ Architecture

### Lightweight U-Net Components:
- **Encoder**: 4 levels with efficient double convolutions
- **Attention Mechanism**: Lightweight channel attention for better feature focus
- **Decoder**: Skip connections for precise line reconstruction
- **Output**: Binary mask (0=background, 1=road lines)

### Model Specifications:
- **Input**: RGB images (256x256)
- **Output**: Binary segmentation mask
- **Parameters**: ~2-5M parameters
- **Size**: 15-25 MB
- **Inference Time**: ~33ms on Jetson Nano

## ğŸ“Š Dataset Structure

```

project/
â”œâ”€â”€ images/          \# Original track images
â”œâ”€â”€ masks/           \# Binary masks (white=lines, black=background)
â””â”€â”€ models/          \# Trained models

```

## ğŸš€ Quick Start

### 1. Installation

```


# Clone repository

 

# Install dependencies

pip install torch torchvision opencv-python numpy matplotlib tqdm scikit-learn

```



## ğŸ“ˆ Training Process

### Data Augmentation
- **Brightness variations**: 0.6-1.4x for different lighting
- **Contrast adjustment**: 0.8-1.3x for line enhancement
- **Saturation changes**: 0.7-1.3x for yellow/white line distinction
- **Rotation**: Â±12Â° for curve simulation
- **Horizontal flip**: 50% probability

### Training Configuration
- **Optimizer**: Adam with weight decay (1e-5)
- **Learning Rate**: 1e-4 with ReduceLROnPlateau
- **Loss Function**: Binary Cross Entropy
- **Early Stopping**: Patience of 12 epochs
- **Batch Size**: 8 (adjustable for GPU memory)

## ğŸ¬ Video Inference

The system processes video frames in real-time and provides:

### Outputs:
- **Binary mask**: Detected road lines
- **Control points**: Left and right line coordinates
- **Steering angle**: Calculated direction for navigation
- **FPS counter**: Real-time performance monitoring
- **Visual overlay**: Lines highlighted on original image

### Control Point Extraction:
```

def extract_control_points(mask):
\# Find contours of detected lines
\# Separate left and right lines
\# Calculate steering angle for MPC/PID
return left_points, right_points, steering_angle

```

## ğŸ“¸ Train Epoch  Preview

### Epoch 2:  
![Original Image](result/lightweight_epoch_002.png)  

### Epoch 20:  
![Original Image](result/lightweight_epoch_020.png) 

### Epoch 34:  
![Original Image](result/lightweight_epoch_034.png) 

### Epoch 50:  
![Original Image](result/lightweight_epoch_050.png)   



## ğŸ“¸ Train Result  Preview

![Original Image](result/lightweight_unet_results.png)  



## ğŸ”§ Jetson Nano Optimization

### Performance Optimizations:
- **TensorRT Integration**: Convert to TensorRT for maximum speed
- **FP16 Precision**: Reduce memory usage and increase speed
- **Batch Size 1**: Optimized for real-time inference
- **Memory Management**: Efficient GPU memory usage


## ğŸ“Š Performance Metrics

| Metric | Value |
|--------|-------|
| Model Size | 15-25 MB |
| Inference Time | ~33ms |
| FPS on Jetson Nano | 30+ |
| Accuracy | 95%+ |
| Memory Usage | <2GB |
 

## ğŸ”¬ Technical Details

### Network Architecture:
```

Input (3, 256, 256)
â†“
Encoder: 32â†’64â†’128â†’256â†’512
â†“
Bottleneck: 512 channels
â†“
Decoder: 512â†’256â†’128â†’64â†’32
â†“
Output (1, 256, 256)

```

### Key Innovations:
- **Lightweight Attention**: Reduces parameters while maintaining accuracy
- **Efficient Convolutions**: Optimized for mobile deployment
- **Smart Augmentation**: Track-specific data enhancement
- **Real-time Pipeline**: End-to-end optimized for speed
 

## ğŸš— Applications

- **Autonomous Racing**: High-speed track navigation
- **Laboratory Testing**: Controlled environment validation
- **Educational Projects**: Computer vision and robotics learning
- **Research Platform**: Algorithm development and testing

 
 

---

**ğŸ Ready for autonomous navigation on your racing track!**
 

